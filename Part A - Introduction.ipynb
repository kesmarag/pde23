{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80b54af",
   "metadata": {},
   "source": [
    "### PyTorch and Tensors\n",
    "PyTorch is an open-source machine learning framework that provides a flexible and dynamic approach to building and training neural networks.\n",
    "\n",
    "\n",
    "- A PyTorch tensor is a multi-dimensional array.\n",
    "- PyTorch tensors share several similarities in syntax and functionality with NumPy arrays.\n",
    "- Tensors in PyTorch support automatic computation of gradients. \n",
    "- The gradients obtain by calling the backward method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7039a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip3 install matplotlib\n",
    "!pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77bdb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# example of a Tensor in PyTorch\n",
    "\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "f = x**3 - x**2 + x + 1.0\n",
    "\n",
    "grad_f = 3.0*x**2 - 2.0*x + 1.0\n",
    "\n",
    "print('manual grad_f(x) =', grad_f.data)\n",
    "\n",
    "f.backward()\n",
    "\n",
    "print('auto grad_f(x)',x.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-cosmetic",
   "metadata": {},
   "source": [
    "### Create a Neural Network in Pytorch - Boilerplate code\n",
    "A neural network is a computational model composed of interconnected nodes and a large number of free parameters, enabling it after the a training phase using data to approximate complex functions\n",
    "\n",
    "\n",
    "\n",
    "- Structure of the network and initialization\n",
    "- Forward pass\n",
    "- Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ANN_Name(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN_Name, self).__init__()\n",
    "      \n",
    "    def forward(self,x):\n",
    "        pass\n",
    "        \n",
    "    def loss(self,x,y):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021334ec",
   "metadata": {},
   "source": [
    "- Our class inherits from torch.nn.Module\n",
    "- In __init__ method we define the parameters (weights and biases) of our model\n",
    "- The forward method performs the forward pass\n",
    "- The loss method calculates the objective function that measures how well the model describes the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-harbor",
   "metadata": {},
   "source": [
    "### A toy example - Simple Linear Regression\n",
    "\n",
    "\\\\( y = w x + b + \\epsilon,\\ \\epsilon \\sim \\mathcal N(0,\\sigma^2)\\\\)\n",
    "\n",
    "Let \\\\(w=2,\\ b=3\\\\), and \\\\(\\sigma=0.05\\\\). We are creating a random sample that consists of \\\\(2^{10}\\\\) pairs.\n",
    "\n",
    "We would like to estimate the parameters \\\\(w,b\\\\) from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-serve",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 2**11\n",
    "\n",
    "x = torch.rand((N,1))               # sample from the uniform distribution in [0,1]\n",
    "epsilon = 0.05*torch.randn(x.shape) # sample from the Gaussian distribution \n",
    "                                    # of zero mean and 0.05 standard deviation\n",
    "y = 2.0*x + 3.0 + epsilon\n",
    "plt.scatter(x,y,s=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-nicaragua",
   "metadata": {},
   "source": [
    "### Least Mean Squares solution - Analytical Approach\n",
    "In the context of linear regression, the goal is to find the best-fitting line that minimizes the sum of squared differences between the predicted values and the actual measured values. \n",
    "\n",
    "\\\\(\\hat y_n = \\hat w x_n + \\hat b \\\\)\n",
    "\n",
    "We can analytically find the parameters that minimizes the MS errors.\n",
    "\n",
    "\\\\[\\mathbf p = \\left[ \\begin{array}{c}\n",
    "\\hat b \\\\\n",
    "\\hat w \n",
    "\\end{array}\\right] = (\\mathbf X^T \\mathbf X)^{-1}\\mathbf X^T \\mathbf y\\\\]\n",
    "where \\\\(\\mathbf X, \\ \\mathbf y\\\\) are given as follows:\n",
    "\\\\[ \\mathbf X= \\left[ \\begin{array}{cc}\n",
    "1 & x_1 \\\\\n",
    "1 & x_2\\\\\n",
    "\\cdots & \\cdots \\\\\n",
    "1 & x_n \\end{array} \\right],\\quad \\mathbf y = \\left[ \\begin{array}{c}\n",
    "y_1 \\\\\n",
    "y_2\\\\\n",
    "\\cdots \\\\\n",
    "y_n \\end{array} \\right]\\\\]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cat([torch.ones(x.shape),x],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.linalg.inv(X.T@X)@X.T@y\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-infection",
   "metadata": {},
   "source": [
    "### Mean Least Squares solution - Neural Network Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(1,1,bias=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat\n",
    "\n",
    "    def loss(self,x,y):\n",
    "        yhat = self.forward(x)\n",
    "        return torch.mean((yhat-y)**2)\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-maximum",
   "metadata": {},
   "source": [
    "#### Training - Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10000\n",
    "\n",
    "for i in range(iterations):\n",
    "    z = model.loss(x,y).backward()\n",
    "    model.linear.weight.data-=0.01*model.linear.weight.grad\n",
    "    model.linear.bias.data-=0.01*model.linear.bias.grad\n",
    "    model.linear.weight.grad.zero_()\n",
    "    model.linear.bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.linear.bias.data)\n",
    "print(model.linear.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y,s=0.1)\n",
    "plt.plot(x,model.forward(x).detach().numpy(),c='red',lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ddd389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(1,1,bias=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        yhat = self.linear(x).reshape(-1,1)\n",
    "        return yhat\n",
    "\n",
    "    def loss(self,x,y):\n",
    "        yhat = self.forward(x)\n",
    "        return torch.mean((yhat-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f259b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat\n",
    "\n",
    "    def loss(self, x, y):\n",
    "        yhat = self.forward(x)\n",
    "        return torch.mean((yhat - y)**2)\n",
    "\n",
    "    def fit(self, x, y, lr=0.01, iterations=10000):\n",
    "        opt = optim.Adam(self.parameters(), lr=lr)\n",
    "        for it in range(iterations):\n",
    "            opt.zero_grad()\n",
    "            loss = self.loss(x, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4096a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.linear.bias.data)\n",
    "print(model.linear.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376fc679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y,s=0.1)\n",
    "plt.plot(x,model.forward(x).detach().numpy(),c='red',lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-handle",
   "metadata": {},
   "source": [
    "### Multivariate Linear Regression\n",
    "\n",
    "Follow the NN approach to train a linear model with two free variables\n",
    "\n",
    "\\\\( y = w_1 x_1 + w_2 x_2 + \\beta + \\epsilon,\\ \\epsilon \\sim \\mathcal N(0,\\sigma^2)\\\\)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d90fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
