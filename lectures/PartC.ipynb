{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e29de240",
   "metadata": {},
   "source": [
    "### Automatic Differentiation using the autograd method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = 2 * x\n",
    "\n",
    "grad = torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y))\n",
    "print(grad) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be6af9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Feynman-Kac\n",
    "\n",
    "The Feynman-Kac theorem allows us to express the solution to the PDE as the expectation of a discounted payoff function of a stochastic process.\n",
    "\n",
    "\\\\[u(x,t) = e^{-rt}\\mathbb{E}_{\\mathbb Q}\\left[(X_T - 1)^+| X_t = x\\right] \\ \\text{to   (PDE + Initial\n",
    "condition)}\\\\]\n",
    "\n",
    "\n",
    "### PDE method - Black-Scholes Model\n",
    "\n",
    "\\\\[x \\in \\mathbb{R}^d_+,\\ t\\in [0,T]\\\\]\n",
    "\n",
    "\\\\[\\frac{\\partial u}{\\partial t} - \\frac{1}{2}\\sigma^2 x^2 \\frac{\\partial^2 u}{\\partial x^2} - rx\\frac{\\partial u}{\\partial x}+ru=0\\\\]\n",
    "\n",
    "\\\\[u(x,0)= (x-1)^+\\\\]\n",
    "\n",
    "To solve the pde numerically we have to restrict the problem to a bounded domain \\\\[\\Omega = [0,3]\\times [0,T]\\\\]\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "\\\\[C(\\theta) = \\left\\|\\frac{\\partial u}{\\partial t}(x,t;\\theta) - \\frac{1}{2}\\sigma^2 x^2 \\frac{\\partial^2 u}{\\partial x^2}(x,t;\\theta) - rx\\frac{\\partial u}{\\partial x}(x,t;\\theta)+ru(x,t;\\theta)\\right\\|_{L^2([0,3]\\times [0,1])}^2 + \\left\\|u(x,0;\\theta) - (x-1)^+\\right\\|_{L^2([0,3])}^2\\\\]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super(ANN, self).__init__()\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        # Parameters of the input layer\n",
    "        self.wi = nn.Linear(n_input,n_hidden,bias=True)\n",
    "        self.wi.weight = nn.Parameter(torch.randn((n_hidden,n_input)))\n",
    "        \n",
    "        # Parameters of the hidden layers\n",
    "        self.wh0 = nn.Linear(n_hidden,n_hidden,bias=True)\n",
    "        self.wh0.weight = nn.Parameter(torch.randn((n_hidden,n_hidden)))\n",
    "        self.wh1 = nn.Linear(n_hidden,n_hidden,bias=True)\n",
    "        self.wh1.weight = nn.Parameter(torch.randn((n_hidden,n_hidden)))\n",
    "        \n",
    "        # Parameters of the output layer\n",
    "        self.wo = nn.Linear(n_hidden,n_output,bias=True)\n",
    "        self.wo.weight = nn.Parameter(torch.randn((n_output,n_hidden)))\n",
    "                \n",
    "    def forward(self, xt):\n",
    "        # Activation function\n",
    "        afunc_tanh = torch.tanh\n",
    "        # Input layer\n",
    "        s0 = self.wi(xt)\n",
    "        y0 = afunc_tanh(s0)\n",
    "        # 1st hidden layer\n",
    "        s1 = self.wh0(y0)\n",
    "        y1 = afunc_tanh(s1)\n",
    "        # 2nd hidden layer\n",
    "        s2 = self.wh1(y1)\n",
    "        y2 = afunc_tanh(s2)\n",
    "        # Output layer\n",
    "        s3 = self.wo(y2)\n",
    "        return s3\n",
    "\n",
    "    \n",
    "class Unsupervised_Model():\n",
    "    def __init__(self, \n",
    "                 ann,   # Neural Network\n",
    "                 T,     # Maturity time\n",
    "                 Xmax,  # Maximum asset price \n",
    "                 r,     # Interest rate\n",
    "                 sigma  # Volatility\n",
    "                ):\n",
    "        self.ann = ann\n",
    "        self.T = T\n",
    "        self.Xmax = Xmax\n",
    "        self.r = r\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def loss(self, xt, x0):\n",
    "        \n",
    "        u = self.ann.forward(xt).reshape(-1,1)\n",
    "        u0 = self.ann.forward(x0).reshape(-1,1)\n",
    "\n",
    "        du = torch.autograd.grad(u,\n",
    "                                 xt,\n",
    "                                 grad_outputs=torch.ones_like(u),\n",
    "                                 create_graph=True)[0]\n",
    "        \n",
    "        dx = du[:,0].reshape(-1,1) # derivative of u wrt x\n",
    "        dt = du[:,1].reshape(-1,1) # derivative of u wrt t\n",
    "        \n",
    "        dxdx = (torch.autograd.grad(dx,\n",
    "                                    xt,\n",
    "                                    grad_outputs=torch.ones_like(dx),\n",
    "                                    create_graph=True)[0])[:,0].reshape(-1,1) # second derivative of u wrt x\n",
    "        \n",
    "        # PDE\n",
    "        norm1 = (dt - 0.5*self.sigma**2 * xt[:,0].reshape(-1,1)* xt[:,0].reshape(-1,1)*dxdx \n",
    "                           - self.r*xt[:,0].reshape(-1,1)*dx+self.r*u)**2\n",
    "        \n",
    "        # Initial Condition\n",
    "        norm2 = (u0-torch.nn.functional.relu(x0[:,0].reshape(-1,1)-1.0))**2\n",
    "        return torch.mean(norm1 + norm2)\n",
    "    \n",
    "    def fit(self, n, iterations, lr=4e-3):\n",
    "        \n",
    "        # Optimization\n",
    "        opt = torch.optim.Adam(self.ann.parameters(), lr)\n",
    "        \n",
    "        for it in range(iterations):\n",
    "            opt.zero_grad()\n",
    "            x = torch.rand((n//2,1))*self.Xmax\n",
    "            t = torch.rand((n//2,1))*self.T\n",
    "            t0 = torch.zeros((n//2,1))\n",
    "            xt = torch.cat([x,t],axis=1).requires_grad_()\n",
    "            x0 = torch.cat([x,t0],axis=1).requires_grad_()\n",
    "            loss = self.loss(xt,x0)\n",
    "            if it % 1000 == 0:\n",
    "                eloss=\"{:e}\".format(loss)\n",
    "                print(it, eloss)\n",
    "            loss.backward()\n",
    "            opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = ANN(2,4,1)\n",
    "model = Unsupervised_Model(ann, 1.0, 3.0, 0.05, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-tablet",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(n=2**12,iterations=2**14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "sigma = 0.5\n",
    "r = 0.05\n",
    "x = np.linspace(0, 3,2**10).reshape(-1,1)\n",
    "t = 1\n",
    "def black_scholes():\n",
    "    ln = np.log(x)\n",
    "    d1 = (ln+(r+0.5*sigma**2)*t)/(sigma*np.sqrt(t))\n",
    "    d2 = (ln+(r-0.5*sigma**2)*t)/(sigma*np.sqrt(t))\n",
    "    bs = x*norm.cdf(d1)-np.exp(-r*t)*norm.cdf(d2)\n",
    "    return bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0.0,3,1024).reshape(-1,1)\n",
    "t = torch.ones((1024)).reshape(-1,1)\n",
    "xt = torch.cat([x,t],axis=1)\n",
    "u = ann.forward(xt)\n",
    "price_formula = black_scholes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,u.detach().numpy(),label='ANN (Unsupervised)')\n",
    "plt.plot(x,price_formula,'--',c='black',label='exact formula')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd4e2b",
   "metadata": {},
   "source": [
    "### European Basket Call Option - Uncorrelated Assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc12a0",
   "metadata": {},
   "source": [
    "\\\\[\\frac{\\partial u}{\\partial t} - \\frac{1}{2}\\sigma_1^2 x^2_1 \\frac{\\partial^2 u}{\\partial x^2_1}\n",
    "- \\frac{1}{2}\\sigma_2^2 x^2_2 \\frac{\\partial^2 u}{\\partial x^2_2}- r\\left(x_1\\frac{\\partial u}{\\partial x_1}+\n",
    "x_2\\frac{\\partial u}{\\partial x_2}\\right)+ru=0\\\\]\n",
    "\n",
    "\\\\[u(x,0)= \\left(\\frac{1}{2}\\sum_{i=1}^2 x_i-1\\right)^+\\\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc7a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
